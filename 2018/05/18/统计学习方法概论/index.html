<!doctype html>



  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>






<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="python," />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.1" />






<meta name="description" content="最近开始重新整理机器学习的内容。 今天总结以下几个内容：  有监督学习、无监督学习的比较、分类和回归方法的比较 过拟合和欠拟合的定义及解决方法 交叉验证 模型评估指标（精确率、召回率、F值、ROC、AUC、Explained_variance、MSE和MSLE）  一、有监督学习、无监督学习、分类和回归方法 ​ 机器学习中有四个主要的分类：  有监督学习(supervised learning)">
<meta name="keywords" content="python">
<meta property="og:type" content="article">
<meta property="og:title" content="统计学习方法概论及Python应用">
<meta property="og:url" content="http://yoursite.com/2018/05/18/统计学习方法概论/index.html">
<meta property="og:site_name" content="彼得的博客">
<meta property="og:description" content="最近开始重新整理机器学习的内容。 今天总结以下几个内容：  有监督学习、无监督学习的比较、分类和回归方法的比较 过拟合和欠拟合的定义及解决方法 交叉验证 模型评估指标（精确率、召回率、F值、ROC、AUC、Explained_variance、MSE和MSLE）  一、有监督学习、无监督学习、分类和回归方法 ​ 机器学习中有四个主要的分类：  有监督学习(supervised learning)">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://yoursite.com/images/download.png">
<meta property="og:image" content="http://yoursite.com/images/download-1.png">
<meta property="og:image" content="http://yoursite.com/images/Screen%20Shot%202018-05-19%20at%2012.41.31%20AM.png">
<meta property="og:image" content="http://yoursite.com/images/download-2.png">
<meta property="og:image" content="http://yoursite.com/images/download-3.png">
<meta property="og:updated_time" content="2018-05-28T13:19:09.821Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="统计学习方法概论及Python应用">
<meta name="twitter:description" content="最近开始重新整理机器学习的内容。 今天总结以下几个内容：  有监督学习、无监督学习的比较、分类和回归方法的比较 过拟合和欠拟合的定义及解决方法 交叉验证 模型评估指标（精确率、召回率、F值、ROC、AUC、Explained_variance、MSE和MSLE）  一、有监督学习、无监督学习、分类和回归方法 ​ 机器学习中有四个主要的分类：  有监督学习(supervised learning)">
<meta name="twitter:image" content="http://yoursite.com/images/download.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    sidebar: {"position":"left","display":"always","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2018/05/18/统计学习方法概论/"/>




<link href="/js/google-code-prettify/prettify.css" type="text/css" rel="stylesheet" />
<link href="/js/google-code-prettify/github-v2.min.css" type="text/css" rel="stylesheet" />

  <title>统计学习方法概论及Python应用 | 彼得的博客</title>
  <script type="text/x-mathjax-config"> MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: "all" } } }); </script>
       <script type="text/x-mathjax-config">
         MathJax.Hub.Config({
           tex2jax: {
             inlineMath: [ ['$','$'], ["\\(","\\)"] ],
             processEscapes: true
           }
         });
       </script>
       <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  














  
  
    
  

  <div class="container sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">彼得的博客</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/05/18/统计学习方法概论/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Peter Tsung">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/pandas.jpeg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="彼得的博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                统计学习方法概论及Python应用
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-05-18T10:41:37+08:00">
                2018-05-18
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-learning/" itemprop="url" rel="index">
                    <span itemprop="name">Machine_learning</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>最近开始重新整理机器学习的内容。</p>
<p>今天总结以下几个内容：</p>
<ol type="1">
<li>有监督学习、无监督学习的比较、分类和回归方法的比较</li>
<li>过拟合和欠拟合的定义及解决方法</li>
<li>交叉验证</li>
<li>模型评估指标（精确率、召回率、F值、ROC、AUC、Explained_variance、MSE和MSLE）</li>
</ol>
<h3 id="一有监督学习无监督学习分类和回归方法">一、有监督学习、无监督学习、分类和回归方法</h3>
<p>​ 机器学习中有四个主要的分类：</p>
<ul>
<li>有监督学习<code>(supervised learning)</code></li>
<li>无监督学习<code>(unsupervised learning)</code></li>
<li>半监督学习<code>(semisupervised learning)</code></li>
<li>强化学习<code>(reinforcement learning)</code>。</li>
</ul>
<p>今天先讲监督学习<code>(supervised learning)</code>和无监督学习 <code>(unsupervised learning)</code>。</p>
<ol type="1">
<li><u>监督学习</u><code>(supervised learning)</code></li>
</ol>
<p>它是由训练数据中学到或者建立一个模式（函数或者是学习模型），使模型能够对任意给定的输入，对其相应的输出做出一个预测。</p>
<p>训练数据通常是一个向量和一个预期输出组成，如果函数的输出是一个连续的数值，则称为回归分析。如果函数的输出是一个分类标签，则称为分类问题<code>(classification)</code>。其中有以下模型：</p>
<blockquote>
<p>​ 决策树 · 表征(Bagging、Boosting、随即森林) · k-NN · 线性回归 · 朴素贝叶斯 · 神经网络 · 逻辑回归 · 感知器 · 支持向量机(SVM) · 相关向量机(RVM)</p>
</blockquote>
<p>现在我们来看点例子吧。</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb1-1" data-line-number="1"><span class="im">from</span> sklearn <span class="im">import</span> linear_model</a>
<a class="sourceLine" id="cb1-2" data-line-number="2"><span class="im">from</span> sklearn <span class="im">import</span> datasets</a>
<a class="sourceLine" id="cb1-3" data-line-number="3"><span class="im">from</span> sklearn.model_selection <span class="im">import</span> cross_val_score</a>
<a class="sourceLine" id="cb1-4" data-line-number="4"><span class="im">from</span> sklearn <span class="im">import</span> svm</a>
<a class="sourceLine" id="cb1-5" data-line-number="5"><span class="im">from</span> sklearn.model_selection <span class="im">import</span> StratifiedKFold</a>
<a class="sourceLine" id="cb1-6" data-line-number="6"></a>
<a class="sourceLine" id="cb1-7" data-line-number="7">iris <span class="op">=</span> datasets.load_iris()</a>
<a class="sourceLine" id="cb1-8" data-line-number="8">iris_X <span class="op">=</span> iris.data</a>
<a class="sourceLine" id="cb1-9" data-line-number="9">iris_y <span class="op">=</span> iris.target</a>
<a class="sourceLine" id="cb1-10" data-line-number="10"></a>
<a class="sourceLine" id="cb1-11" data-line-number="11"><span class="co"># 打印分数</span></a>
<a class="sourceLine" id="cb1-12" data-line-number="12"><span class="kw">def</span> display_scores(scores):</a>
<a class="sourceLine" id="cb1-13" data-line-number="13">    <span class="bu">print</span>(<span class="st">&quot;Scores : &quot;</span>, scores)</a>
<a class="sourceLine" id="cb1-14" data-line-number="14">    <span class="bu">print</span>(<span class="st">&quot;Mean : </span><span class="sc">%.2f</span><span class="st">&quot;</span> <span class="op">%</span> scores.mean())</a>
<a class="sourceLine" id="cb1-15" data-line-number="15">    <span class="bu">print</span>(<span class="st">&quot;Accuracy: </span><span class="sc">%0.2f</span><span class="st"> (+/- </span><span class="sc">%0.2f</span><span class="st">)&quot;</span> <span class="op">%</span> (scores.mean(), scores.std() <span class="op">*</span> <span class="dv">2</span>))</a>
<a class="sourceLine" id="cb1-16" data-line-number="16"></a>
<a class="sourceLine" id="cb1-17" data-line-number="17"><span class="co"># 输入model，X，y</span></a>
<a class="sourceLine" id="cb1-18" data-line-number="18"><span class="co"># 输出分数</span></a>
<a class="sourceLine" id="cb1-19" data-line-number="19"><span class="kw">def</span> model_scores(model, X, y):</a>
<a class="sourceLine" id="cb1-20" data-line-number="20">    cv <span class="op">=</span> StratifiedKFold(n_splits<span class="op">=</span><span class="dv">5</span>, random_state<span class="op">=</span><span class="dv">0</span>)</a>
<a class="sourceLine" id="cb1-21" data-line-number="21">    scores <span class="op">=</span> cross_val_score(model, X, y, cv<span class="op">=</span>cv)</a>
<a class="sourceLine" id="cb1-22" data-line-number="22">    display_scores(scores)</a>
<a class="sourceLine" id="cb1-23" data-line-number="23">    </a>
<a class="sourceLine" id="cb1-24" data-line-number="24"><span class="co"># LinearRegression</span></a>
<a class="sourceLine" id="cb1-25" data-line-number="25">reg <span class="op">=</span> linear_model.LinearRegression()</a>
<a class="sourceLine" id="cb1-26" data-line-number="26">model_scores(reg, iris_X, iris_y)</a>
<a class="sourceLine" id="cb1-27" data-line-number="27">[output]</a>
<a class="sourceLine" id="cb1-28" data-line-number="28">Scores :  [<span class="fl">0.93427277</span> <span class="fl">0.9395803</span>  <span class="fl">0.89930025</span> <span class="fl">0.90288946</span> <span class="fl">0.95617435</span>]</a>
<a class="sourceLine" id="cb1-29" data-line-number="29">Mean : <span class="fl">0.93</span></a>
<a class="sourceLine" id="cb1-30" data-line-number="30">Accuracy: <span class="fl">0.93</span> (<span class="op">+/-</span> <span class="fl">0.04</span>)</a>
<a class="sourceLine" id="cb1-31" data-line-number="31"></a>
<a class="sourceLine" id="cb1-32" data-line-number="32"><span class="co"># Logistic Regression</span></a>
<a class="sourceLine" id="cb1-33" data-line-number="33">logistic <span class="op">=</span> linear_model.LogisticRegression(C<span class="op">=</span><span class="fl">1e5</span>)</a>
<a class="sourceLine" id="cb1-34" data-line-number="34">model_scores(logistic, iris_X, iris_y)</a>
<a class="sourceLine" id="cb1-35" data-line-number="35">[output]</a>
<a class="sourceLine" id="cb1-36" data-line-number="36">Scores :  [<span class="fl">0.96666667</span> <span class="fl">0.96666667</span> <span class="fl">0.93333333</span> <span class="fl">0.93333333</span> <span class="fl">1.</span>        ]</a>
<a class="sourceLine" id="cb1-37" data-line-number="37">Mean : <span class="fl">0.96</span></a>
<a class="sourceLine" id="cb1-38" data-line-number="38">Accuracy: <span class="fl">0.96</span> (<span class="op">+/-</span> <span class="fl">0.05</span>)</a>
<a class="sourceLine" id="cb1-39" data-line-number="39"></a>
<a class="sourceLine" id="cb1-40" data-line-number="40"><span class="co"># SVM</span></a>
<a class="sourceLine" id="cb1-41" data-line-number="41">clf <span class="op">=</span> svm.SVC(kernel<span class="op">=</span><span class="st">&#39;linear&#39;</span>, C<span class="op">=</span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb1-42" data-line-number="42">model_scores(clf, iris_X, iris_y)</a>
<a class="sourceLine" id="cb1-43" data-line-number="43">[output]</a>
<a class="sourceLine" id="cb1-44" data-line-number="44">Scores :  [<span class="fl">0.96666667</span> <span class="fl">1.</span>         <span class="fl">0.96666667</span> <span class="fl">0.96666667</span> <span class="fl">1.</span>        ]</a>
<a class="sourceLine" id="cb1-45" data-line-number="45">Mean : <span class="fl">0.98</span></a>
<a class="sourceLine" id="cb1-46" data-line-number="46">Accuracy: <span class="fl">0.98</span> (<span class="op">+/-</span> <span class="fl">0.03</span>)</a></code></pre></div>
<ol start="2" type="1">
<li><u>无监督学习</u><code>(unsupervised learning)</code></li>
</ol>
<p>无监督学习没有输入标签，一种常见的无监督学习就是数据聚类，在人工神经网络中，生成对抗网络<code>(GAN)</code>、自组织映射<code>(SOM)</code>和适应性共振理论<code>(ART)</code>则是最常用的无监督学习。在聚类中，主要有以下模型：</p>
<blockquote>
<p>BIRCH · Hierarchical clustering · k平均 · 期望最大化（EM）· DBSCAN · OPTICS · 均值飘逸(Mean shifit)</p>
</blockquote>
<p>现在我们来看些例子吧。</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb2-1" data-line-number="1"><span class="op">%</span>matplotlib inline</a>
<a class="sourceLine" id="cb2-2" data-line-number="2"><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</a>
<a class="sourceLine" id="cb2-3" data-line-number="3"><span class="im">import</span> seaborn <span class="im">as</span> sns<span class="op">;</span> sns.<span class="bu">set</span>()</a>
<a class="sourceLine" id="cb2-4" data-line-number="4"><span class="im">import</span> numpy <span class="im">as</span> np</a>
<a class="sourceLine" id="cb2-5" data-line-number="5"><span class="im">from</span> sklearn.cluster <span class="im">import</span> KMeans</a>
<a class="sourceLine" id="cb2-6" data-line-number="6"></a>
<a class="sourceLine" id="cb2-7" data-line-number="7"><span class="im">from</span> sklearn.datasets.samples_generator <span class="im">import</span> make_blobs</a>
<a class="sourceLine" id="cb2-8" data-line-number="8">X, y_true <span class="op">=</span> make_blobs(n_samples<span class="op">=</span><span class="dv">300</span>, centers<span class="op">=</span><span class="dv">4</span>,</a>
<a class="sourceLine" id="cb2-9" data-line-number="9">                      cluster_std<span class="op">=</span><span class="fl">0.60</span>, random_state<span class="op">=</span><span class="dv">0</span>)</a>
<a class="sourceLine" id="cb2-10" data-line-number="10">plt.scatter(X[:, <span class="dv">0</span>], X[:, <span class="dv">1</span>], s<span class="op">=</span><span class="dv">50</span>)</a>
<a class="sourceLine" id="cb2-11" data-line-number="11"></a>
<a class="sourceLine" id="cb2-12" data-line-number="12">kmeans <span class="op">=</span> KMeans(n_clusters<span class="op">=</span><span class="dv">4</span>)</a>
<a class="sourceLine" id="cb2-13" data-line-number="13">kmeans.fit(X)</a>
<a class="sourceLine" id="cb2-14" data-line-number="14">y_kmeans <span class="op">=</span> kmeans.predict(X)</a>
<a class="sourceLine" id="cb2-15" data-line-number="15"></a>
<a class="sourceLine" id="cb2-16" data-line-number="16">plt.scatter(X[:, <span class="dv">0</span>], X[:, <span class="dv">1</span>], c<span class="op">=</span>y_kmeans, s<span class="op">=</span><span class="dv">50</span>, cmap<span class="op">=</span><span class="st">&#39;viridis&#39;</span>)</a>
<a class="sourceLine" id="cb2-17" data-line-number="17"></a>
<a class="sourceLine" id="cb2-18" data-line-number="18">centers <span class="op">=</span> kmeans.cluster_centers_</a>
<a class="sourceLine" id="cb2-19" data-line-number="19">plt.scatter(centers[:, <span class="dv">0</span>], centers[:, <span class="dv">1</span>], c<span class="op">=</span><span class="st">&#39;black&#39;</span>, s<span class="op">=</span><span class="dv">200</span>, alpha<span class="op">=</span><span class="fl">0.5</span>)</a></code></pre></div>
<p><img src="/images/download.png"><img src="/images/download-1.png"></p>
<ol start="3" type="1">
<li>回归和分类的比较</li>
</ol>
<p>在上面已经针对回归和分类有了一个比较通俗的解读：如果函数的输出是一个连续的数值，则称为回归分析。如果函数的输出是一个分类标签，则称为分类问题<code>(classification)</code>。</p>
<p>回归方法一览：</p>
<blockquote>
<p>SGD Regressor · Lasso · ElasticNet · RidgeRegression · SVR(kernel=‘linear’ · SVR(kernel=‘rbf’) · EnsembleRegressors</p>
</blockquote>
<p>分类方法一览：</p>
<blockquote>
<p>SGD Classifier · Linear SVC · KNeighbors Classifier · kernel approximation · SVC · Ensemble Classifiers · Naive Bayes</p>
</blockquote>
<h3 id="二overfitting与underfitting定义及解决方法">二、<code>overfitting</code>与<code>underfitting</code>定义及解决方法</h3>
<p><code>方差</code>：方差度量了同样大小的训练集变动所导致的学习性能变化，即刻画了数据扰动所造成的影响。</p>
<p><code>偏差</code>: 偏差度量了学习算法的期望预测真是结果的偏离程度，即刻画了学习算法本身的拟合能力。</p>
<p><code>噪声</code>: 噪声表达了在当前任务上任何学习算法所能达到的期望泛化误差的下界，即刻画了学习问题本身的难度。</p>
<h3 id="underfitting欠拟合"><u>underfitting欠拟合</u></h3>
<p><strong>定义</strong>：欠拟合指的是模型并没有很好地捕捉到数据特征，不能很好地拟合数据。</p>
<p><strong>特点</strong>：</p>
<ol type="1">
<li>模型的方差<code>variance</code>较小，预测输出和期望输出的差值较小</li>
<li>偏差<code>bias</code>较大，期望预测和真实值的差值较大</li>
<li>模型复杂度较小</li>
</ol>
<p><strong>解决方法</strong>：</p>
<ol type="1">
<li>添加其他特征项（可通过组合、泛化和相关性这三种手段）</li>
<li>添加多项式特征，增加模型复杂度</li>
<li>减少正则化参数，减少对复杂模型的惩罚</li>
<li>增加更多的数据</li>
</ol>
<h3 id="overfitting-过拟合"><u>overfitting 过拟合</u></h3>
<p><strong>定义</strong>：过拟合指的是模型对数据的太过拟合，对新的数据泛化能力较差</p>
<p><strong>特点</strong>：</p>
<ol type="1">
<li>模型的方差<code>variance</code>较大，预测输出和期望输出的差值较大</li>
<li>偏差<code>bias</code>一般较大，期望预测和真实值的差值一般较大</li>
<li>模型复杂度较大</li>
</ol>
<p><strong>解决方法</strong>：</p>
<ol type="1">
<li>重新清洗数据</li>
<li>增大数据的训练量</li>
<li>采用正则化</li>
<li>采用<code>Dropout</code>方法，在训练时让神经元以一定的概率不工作</li>
</ol>
<h3 id="三交叉验证cross-validation">三、交叉验证(cross validation)</h3>
<p>其实在上面的例子中， 我们已经使用了交叉验证。交叉验证直白地说就是为了验证模型的表现。学习预测函数的参数并且在相同的数据中测试它是一种错误的方法：因为只重复看到的样本标签的模型本身会有一个完美的表现，但它并不能预测任何有用的信息，对于未见过的数据，模型的泛化能力会非常差。这种情况称为过拟合。</p>
<p>为了避免这种情况，对于有监督学习，通常会将数据集划分为训练集和测试集，然后进行模型表现的评估。这种做法称为交叉验证。</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb3-1" data-line-number="1"><span class="im">import</span> numpy <span class="im">as</span> np</a>
<a class="sourceLine" id="cb3-2" data-line-number="2"><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</a>
<a class="sourceLine" id="cb3-3" data-line-number="3"><span class="im">from</span> sklearn <span class="im">import</span> datasets</a>
<a class="sourceLine" id="cb3-4" data-line-number="4"><span class="im">from</span> sklearn <span class="im">import</span> svm</a>
<a class="sourceLine" id="cb3-5" data-line-number="5"></a>
<a class="sourceLine" id="cb3-6" data-line-number="6">iris <span class="op">=</span> datasets.load_iris()</a>
<a class="sourceLine" id="cb3-7" data-line-number="7">iris_X <span class="op">=</span> iris.data</a>
<a class="sourceLine" id="cb3-8" data-line-number="8">iris_y <span class="op">=</span> iris.target</a>
<a class="sourceLine" id="cb3-9" data-line-number="9"></a>
<a class="sourceLine" id="cb3-10" data-line-number="10">X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(</a>
<a class="sourceLine" id="cb3-11" data-line-number="11">    iris_X, iris_y, test_size<span class="op">=</span><span class="fl">0.4</span>, random_state<span class="op">=</span><span class="dv">0</span></a>
<a class="sourceLine" id="cb3-12" data-line-number="12">)</a>
<a class="sourceLine" id="cb3-13" data-line-number="13"></a>
<a class="sourceLine" id="cb3-14" data-line-number="14">clf <span class="op">=</span> svm.SVC(kernel<span class="op">=</span><span class="st">&#39;linear&#39;</span>, C<span class="op">=</span><span class="dv">1</span>).fit(X_train, y_train)</a>
<a class="sourceLine" id="cb3-15" data-line-number="15"><span class="bu">print</span>(clf.score(X_test, y_test))</a>
<a class="sourceLine" id="cb3-16" data-line-number="16">[output]</a>
<a class="sourceLine" id="cb3-17" data-line-number="17"><span class="fl">0.9666666666666667</span></a></code></pre></div>
<p>常见的交叉验证有：</p>
<ul>
<li>Holdout验证：随机从最初样本选取部分，形成交叉验证数据，而剩余的就当作训练数据。一般来说，少于原样本三分之一的数据被选作验证数据。</li>
<li>K-Fold交叉验证</li>
</ul>
<p>K次交叉验证，将训练集分割成K个子样本， 一个单独的子样本被保留作为验证模型的数据，其他K-1个样本用作训练。交叉验证重复K次，每个子样本验证一次。这种方法的优势在于，同时重复运用随机产生的子样本进行训练和验证，每次的结果验证一次，10次交叉验证是最常用的。</p>
<ul>
<li>留一验证（LOOCV）</li>
</ul>
<p>事实上这跟K-Fold是一样的，只不过这里的K是样本个数。</p>
<p>常见的误差估计：均方差和方根均方差。</p>
<h3 id="四模型评估指标精确率召回率f值rocauc">四、模型评估指标（精确率、召回率、F值、ROC、AUC）</h3>
<p>首先我们来看一张<code>sklearn</code>上模型评估指标。</p>
<p><img src="/images/Screen%20Shot%202018-05-19%20at%2012.41.31%20AM.png"></p>
<p>对于<strong><u>分类问题</u></strong>，一般使用<code>accuracy</code>、<code>f1</code>、<code>neg_log_loss</code>、<code>recall</code>和<code>roc_auc</code></p>
<ol type="1">
<li><code>recall</code>、<code>precision</code>、<code>accuracy</code>和<code>f1</code></li>
</ol>
<table>
<thead>
<tr class="header">
<th style="text-align: center;"></th>
<th style="text-align: center;">预测结果</th>
<th style="text-align: center;"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><strong>真实结果</strong></td>
<td style="text-align: center;">正例（Yes）</td>
<td style="text-align: center;">反例（No）</td>
</tr>
<tr class="even">
<td style="text-align: center;">正例（Yes）</td>
<td style="text-align: center;">TP</td>
<td style="text-align: center;">FN</td>
</tr>
<tr class="odd">
<td style="text-align: center;">反例（No）</td>
<td style="text-align: center;">FP</td>
<td style="text-align: center;">TN</td>
</tr>
</tbody>
</table>
<p><span class="math display">\[
\begin{aligned}
Precision\ \ (P)  &amp; = \frac {TP}{TP + FP} \\
\\
Recall\ \ (R) &amp; = \frac {TP}{TP + FN} \\
\\
F1 = \frac{2P \cdot R}{P + R} &amp; = \frac{2TP}{2TP+FP+FN} \\
\\
Accuracy &amp; = \frac{TP+TN}{TP+TN+FN+FP}
\end{aligned}
\]</span></p>
<ul>
<li><code>查准率(Precision)</code>: 指在所有预测为正例的情况中，预测正例且实际正例的比例。<code>查准率</code>关注的是预测正例正确占所有预测为正例情况的比例，白话文就是说，<code>查准率</code>关注的是你预测了一大堆正例的例子，然后里面有多少是预测正确的，就是准不准嘛。</li>
<li><code>查全率(Recall)</code>: 指在实际为正例的情况中，预测为正例的比例。白话文就是说，<code>查全率</code>关注的是你正确预测了一大堆正例，数量为A，真实情况下正例的数量是B，然后看B里面有多少比例的A，然后去判断预测正确的情况全不全。</li>
</ul>
<div class="sourceCode" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb4-1" data-line-number="1"><span class="im">from</span> sklearn <span class="im">import</span> svm, datasets</a>
<a class="sourceLine" id="cb4-2" data-line-number="2"><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</a>
<a class="sourceLine" id="cb4-3" data-line-number="3"><span class="im">import</span> numpy <span class="im">as</span> np</a>
<a class="sourceLine" id="cb4-4" data-line-number="4"><span class="im">from</span> sklearn.metrics <span class="im">import</span> average_precision_score, precision_recall_curve</a>
<a class="sourceLine" id="cb4-5" data-line-number="5"><span class="im">from</span> sklearn.metrics <span class="im">import</span> precision_score, recall_score</a>
<a class="sourceLine" id="cb4-6" data-line-number="6"><span class="im">from</span> sklearn.metrics <span class="im">import</span> classification_report</a>
<a class="sourceLine" id="cb4-7" data-line-number="7"><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</a>
<a class="sourceLine" id="cb4-8" data-line-number="8"></a>
<a class="sourceLine" id="cb4-9" data-line-number="9"></a>
<a class="sourceLine" id="cb4-10" data-line-number="10">iris <span class="op">=</span> datasets.load_iris()</a>
<a class="sourceLine" id="cb4-11" data-line-number="11">X <span class="op">=</span> iris.data</a>
<a class="sourceLine" id="cb4-12" data-line-number="12">y <span class="op">=</span> iris.target</a>
<a class="sourceLine" id="cb4-13" data-line-number="13"></a>
<a class="sourceLine" id="cb4-14" data-line-number="14">random_state <span class="op">=</span> np.random.RandomState(<span class="dv">0</span>)</a>
<a class="sourceLine" id="cb4-15" data-line-number="15">n_samples, n_features <span class="op">=</span> X.shape</a>
<a class="sourceLine" id="cb4-16" data-line-number="16">X <span class="op">=</span> np.c_[X, random_state.randn(n_samples, <span class="dv">200</span> <span class="op">*</span> n_features)]</a>
<a class="sourceLine" id="cb4-17" data-line-number="17"></a>
<a class="sourceLine" id="cb4-18" data-line-number="18">X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X[y <span class="op">&lt;</span> <span class="dv">2</span>], y[y <span class="op">&lt;</span> <span class="dv">2</span>],</a>
<a class="sourceLine" id="cb4-19" data-line-number="19">                                                    test_size<span class="op">=</span>.<span class="dv">5</span>,</a>
<a class="sourceLine" id="cb4-20" data-line-number="20">                                                   random_state<span class="op">=</span>random_state)</a>
<a class="sourceLine" id="cb4-21" data-line-number="21"></a>
<a class="sourceLine" id="cb4-22" data-line-number="22">clf <span class="op">=</span> svm.LinearSVC(random_state<span class="op">=</span>random_state)</a>
<a class="sourceLine" id="cb4-23" data-line-number="23">clf.fit(X_train, y_train)</a>
<a class="sourceLine" id="cb4-24" data-line-number="24">y_score <span class="op">=</span> clf.decision_function(X_test)</a>
<a class="sourceLine" id="cb4-25" data-line-number="25"></a>
<a class="sourceLine" id="cb4-26" data-line-number="26">average_precision <span class="op">=</span> average_precision_score(y_test, y_score)</a>
<a class="sourceLine" id="cb4-27" data-line-number="27"><span class="bu">print</span>(<span class="st">&#39;Average precision-recall score: </span><span class="sc">{0:0.2f}</span><span class="st">&#39;</span>.<span class="bu">format</span>(average_precision))</a>
<a class="sourceLine" id="cb4-28" data-line-number="28">[output]</a>
<a class="sourceLine" id="cb4-29" data-line-number="29">Average precision<span class="op">-</span>recall score: <span class="fl">0.88</span></a>
<a class="sourceLine" id="cb4-30" data-line-number="30">    </a>
<a class="sourceLine" id="cb4-31" data-line-number="31"><span class="bu">print</span>(precision_score(y_test, clf.predict(X_test)))</a>
<a class="sourceLine" id="cb4-32" data-line-number="32"><span class="bu">print</span>(recall_score(y_test, clf.predict(X_test)))</a>
<a class="sourceLine" id="cb4-33" data-line-number="33"><span class="bu">print</span>(f1_score(y_test, clf.predict(X_test)))</a>
<a class="sourceLine" id="cb4-34" data-line-number="34"><span class="bu">print</span>(classification_report(y_test, clf.predict(X_test)))</a>
<a class="sourceLine" id="cb4-35" data-line-number="35">[output]</a>
<a class="sourceLine" id="cb4-36" data-line-number="36"><span class="fl">0.75</span></a>
<a class="sourceLine" id="cb4-37" data-line-number="37"><span class="fl">0.8076923076923077</span></a>
<a class="sourceLine" id="cb4-38" data-line-number="38"><span class="fl">0.7777777777777779</span></a>
<a class="sourceLine" id="cb4-39" data-line-number="39"></a>
<a class="sourceLine" id="cb4-40" data-line-number="40">            precision    recall  f1<span class="op">-</span>score   support</a>
<a class="sourceLine" id="cb4-41" data-line-number="41"></a>
<a class="sourceLine" id="cb4-42" data-line-number="42">          <span class="dv">0</span>       <span class="fl">0.77</span>      <span class="fl">0.71</span>      <span class="fl">0.74</span>        <span class="dv">24</span></a>
<a class="sourceLine" id="cb4-43" data-line-number="43">          <span class="dv">1</span>       <span class="fl">0.75</span>      <span class="fl">0.81</span>      <span class="fl">0.78</span>        <span class="dv">26</span></a>
<a class="sourceLine" id="cb4-44" data-line-number="44"></a>
<a class="sourceLine" id="cb4-45" data-line-number="45">avg <span class="op">/</span> total       <span class="fl">0.76</span>      <span class="fl">0.76</span>      <span class="fl">0.76</span>        <span class="dv">50</span></a>
<a class="sourceLine" id="cb4-46" data-line-number="46"></a>
<a class="sourceLine" id="cb4-47" data-line-number="47"></a>
<a class="sourceLine" id="cb4-48" data-line-number="48">precision, recall, _ <span class="op">=</span> precision_recall_curve(y_test, y_score)</a>
<a class="sourceLine" id="cb4-49" data-line-number="49">plt.step(recall, precision, color<span class="op">=</span><span class="st">&#39;b&#39;</span>, alpha<span class="op">=</span><span class="fl">0.2</span>,</a>
<a class="sourceLine" id="cb4-50" data-line-number="50">        where<span class="op">=</span><span class="st">&#39;post&#39;</span>)</a>
<a class="sourceLine" id="cb4-51" data-line-number="51">plt.fill_between(recall, precision, step<span class="op">=</span><span class="st">&#39;post&#39;</span>, alpha<span class="op">=</span><span class="fl">0.2</span>,</a>
<a class="sourceLine" id="cb4-52" data-line-number="52">                color<span class="op">=</span><span class="st">&#39;b&#39;</span>)</a>
<a class="sourceLine" id="cb4-53" data-line-number="53"></a>
<a class="sourceLine" id="cb4-54" data-line-number="54">plt.xlabel(<span class="st">&#39;Recall&#39;</span>)</a>
<a class="sourceLine" id="cb4-55" data-line-number="55">plt.ylabel(<span class="st">&#39;Precision&#39;</span>)</a>
<a class="sourceLine" id="cb4-56" data-line-number="56">plt.ylim([<span class="fl">0.0</span>, <span class="fl">1.05</span>])</a>
<a class="sourceLine" id="cb4-57" data-line-number="57">plt.xlim([<span class="fl">0.0</span>, <span class="fl">1.0</span>])</a>
<a class="sourceLine" id="cb4-58" data-line-number="58">plt.title(<span class="st">&#39;2-class Precision-Recall curve: AP=</span><span class="sc">{0:0.2f}</span><span class="st">&#39;</span>.<span class="bu">format</span>(average_precision))    </a></code></pre></div>
<p><img src="/images/download-2.png"></p>
<ul>
<li><code>准确率(Accuracuy)</code>: 对于给定的测试集数据，分类器正确分类的样本数与总样本之比。</li>
</ul>
<div class="sourceCode" id="cb5"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb5-1" data-line-number="1"><span class="im">import</span> numpy <span class="im">as</span> np</a>
<a class="sourceLine" id="cb5-2" data-line-number="2"><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score</a>
<a class="sourceLine" id="cb5-3" data-line-number="3">y_pred <span class="op">=</span> [<span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">3</span>]</a>
<a class="sourceLine" id="cb5-4" data-line-number="4">y_true <span class="op">=</span> [<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>]</a>
<a class="sourceLine" id="cb5-5" data-line-number="5"><span class="bu">print</span>(accuracy_score(y_true, y_pred))</a>
<a class="sourceLine" id="cb5-6" data-line-number="6">[output]</a>
<a class="sourceLine" id="cb5-7" data-line-number="7"><span class="fl">0.5</span></a></code></pre></div>
<ol start="2" type="1">
<li><code>ROC</code>和<code>AUC</code></li>
</ol>
<p><strong><u>ROC(Receiver operating characteristic)和AUC(Area Under ROC Curve)</u></strong></p>
<p>ROC曲线是二值分类器常用的工具，是反映敏感性和特异性连续变量的综合指标，roc曲线上每个点反映着对同一信号刺激的感受性。</p>
<p>它跟<code>precision/recall</code>曲线非常相似，只不过ROC曲线描绘的是TPR(True Positive Rate，Recall另一种叫法)和FPR(False Positive Rate)的关系。</p>
<p>在我看来，ROC曲线更多的描述多个模型的性能比较，如果一个模型A的ROC曲线被另一个模型B的ROC包围，那很明显另外一个模型B的表现优于模型A。因此比较ROC曲线下的面积，即AUC(Area Under ROC Curve) <span class="math display">\[
\begin{aligned}
Recall\ \ (R) &amp; = TPR =  \frac {TP}{TP + FN} \\
\\
FPR  &amp;= \frac{FP}{FP + TN} \\\\
&amp;= 1 - TNR  \\\\ 
&amp; = 1 - \frac{TN}{FP+TN} \\\\
&amp;= 1-specificity
\end{aligned}
\]</span> ROC曲线有个很好的特性：当测试集中的正负样本的分布变换的时候，ROC曲线能够保持不变。在实际的数据集中经常会出现样本类不平衡，即正负样本比例差距较大，而且测试数据中的正负样本也可能随着时间变化。</p>
<p>理想情况下，TPR应该接近1，FPR应该接近0。故ROC曲线越靠拢(0,1)点，越偏离45度对角线越好，Sensitivity、Specificity越大效果越好。</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb6-1" data-line-number="1"><span class="im">from</span> sklearn.metrics <span class="im">import</span> roc_curve</a>
<a class="sourceLine" id="cb6-2" data-line-number="2">fpr, tpr, thresholds <span class="op">=</span> roc_curve(y_test, clf.predict(X_test))</a>
<a class="sourceLine" id="cb6-3" data-line-number="3"><span class="kw">def</span> plot_roc_curve(fpr, tpr, label<span class="op">=</span><span class="va">None</span>):</a>
<a class="sourceLine" id="cb6-4" data-line-number="4">    plt.plot(fpr, tpr, linewidth<span class="op">=</span><span class="dv">2</span>, label<span class="op">=</span>label)</a>
<a class="sourceLine" id="cb6-5" data-line-number="5">    plt.plot([<span class="dv">0</span>, <span class="dv">1</span>], [<span class="dv">0</span>, <span class="dv">1</span>], <span class="st">&#39;k--&#39;</span>)</a>
<a class="sourceLine" id="cb6-6" data-line-number="6">    plt.axis([<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>])</a>
<a class="sourceLine" id="cb6-7" data-line-number="7">    plt.xlabel(<span class="st">&#39;False Positive Rate&#39;</span>)</a>
<a class="sourceLine" id="cb6-8" data-line-number="8">    plt.ylabel(<span class="st">&#39;True Positive Rate&#39;</span>)</a>
<a class="sourceLine" id="cb6-9" data-line-number="9">    </a>
<a class="sourceLine" id="cb6-10" data-line-number="10">plot_roc_curve(fpr, tpr)</a>
<a class="sourceLine" id="cb6-11" data-line-number="11">plt.show()</a></code></pre></div>
<p><img src="/images/download-3.png"></p>
<ol start="3" type="1">
<li><code>neg_log_loss</code></li>
</ol>
<p>对于<code>log_loss</code>，它计算的是交叉熵。</p>
<p>对于<u>回归问题</u>，一般使用<code>explained_variance_score</code>、<code>Mean squared error</code>、<code>neg_mean_squared_log_error</code></p>
<ol type="1">
<li><code>Explained_variance_score</code></li>
</ol>
<p>最好的表现是1， 数值越低表现越差 <span class="math display">\[
explained_variance(y,  \hat y) = 1- \frac{Var\{y - \hat y\}}{Var\{y\} }
\]</span></p>
<div class="sourceCode" id="cb7"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb7-1" data-line-number="1"><span class="im">from</span> sklearn.metrics <span class="im">import</span> explained_variance_score</a>
<a class="sourceLine" id="cb7-2" data-line-number="2">y_true <span class="op">=</span> [<span class="dv">3</span>, <span class="fl">-0.5</span>, <span class="dv">2</span>, <span class="dv">7</span>]</a>
<a class="sourceLine" id="cb7-3" data-line-number="3">y_pred <span class="op">=</span> [<span class="fl">2.5</span>, <span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">8</span>]</a>
<a class="sourceLine" id="cb7-4" data-line-number="4"><span class="bu">print</span>(explained_variance_score(y_true, y_pred))</a>
<a class="sourceLine" id="cb7-5" data-line-number="5">[output]</a>
<a class="sourceLine" id="cb7-6" data-line-number="6"><span class="fl">0.9571734475374732</span></a></code></pre></div>
<ol start="2" type="1">
<li><code>Mean squared error(MSE)</code></li>
</ol>
<p>MSE越小，模型拟合表现越好。 <span class="math display">\[
MSE(y, \hat y) = \frac{1}{n_{samples}} \sum^{n_{samples} - 1}_{i=0} \ \ (y_i - \hat y_i) ^ 2
\]</span></p>
<div class="sourceCode" id="cb8"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb8-1" data-line-number="1"><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_squared_error</a>
<a class="sourceLine" id="cb8-2" data-line-number="2">y_true <span class="op">=</span> [<span class="dv">3</span>, <span class="fl">-0.5</span>, <span class="dv">2</span>, <span class="dv">7</span>]</a>
<a class="sourceLine" id="cb8-3" data-line-number="3">y_pred <span class="op">=</span> [<span class="fl">2.5</span>, <span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">8</span>]</a>
<a class="sourceLine" id="cb8-4" data-line-number="4"><span class="bu">print</span>(mean_squared_error(y_true, y_pred))</a>
<a class="sourceLine" id="cb8-5" data-line-number="5">[output]</a>
<a class="sourceLine" id="cb8-6" data-line-number="6"><span class="fl">0.375</span></a></code></pre></div>
<ol start="3" type="1">
<li><code>Mean_squared_log_error(MSLE)</code></li>
</ol>
<p>MSLE越小，模型拟合表现越好。当两个数值都是巨大数字时，如果不想惩罚巨大的差异，就可以使用它。当具有指数增长的目标（如人口数量，商品在一定年限内的平均销售额等）时，最好使用此度量标准。请注意，此度量标准对低于预测的估算值的惩罚高于超出预测的估算值。 <span class="math display">\[
MSLE(y, \hat y) = \frac{1}{n_{samples}} \sum_{i=0}^{n_{samples}-1} (log_e(1+y_i) - log_e(1 + \hat y_i))^ 2
\]</span></p>
<div class="sourceCode" id="cb9"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb9-1" data-line-number="1"><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_squared_log_error</a>
<a class="sourceLine" id="cb9-2" data-line-number="2">y_true <span class="op">=</span> [<span class="dv">3</span>, <span class="dv">5</span>, <span class="fl">2.5</span>, <span class="dv">7</span>]</a>
<a class="sourceLine" id="cb9-3" data-line-number="3">y_pred <span class="op">=</span> [<span class="fl">2.5</span>, <span class="dv">5</span>, <span class="dv">4</span>, <span class="dv">8</span>]</a>
<a class="sourceLine" id="cb9-4" data-line-number="4"><span class="bu">print</span>(mean_squared_log_error(y_true, y_pred))</a>
<a class="sourceLine" id="cb9-5" data-line-number="5">[output]</a>
<a class="sourceLine" id="cb9-6" data-line-number="6"><span class="fl">0.0397</span></a></code></pre></div>

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/python/" rel="tag"># python</a>
          
        </div>
      

      
        
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/04/07/TF-IDF/" rel="next" title="TF-IDF">
                <i class="fa fa-chevron-left"></i> TF-IDF
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/05/20/Perceptron/" rel="prev" title="Perceptron">
                Perceptron <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/pandas.jpeg"
               alt="Peter Tsung" />
          <p class="site-author-name" itemprop="name">Peter Tsung</p>
           
              <p class="site-description motion-element" itemprop="description">I Never Save Anything For The Swim Back.</p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">41</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">8</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">7</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#一有监督学习无监督学习分类和回归方法"><span class="nav-number">1.</span> <span class="nav-text">一、有监督学习、无监督学习、分类和回归方法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#二overfitting与underfitting定义及解决方法"><span class="nav-number">2.</span> <span class="nav-text">二、overfitting与underfitting定义及解决方法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#underfitting欠拟合"><span class="nav-number">3.</span> <span class="nav-text">underfitting欠拟合</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#overfitting-过拟合"><span class="nav-number">4.</span> <span class="nav-text">overfitting 过拟合</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#三交叉验证cross-validation"><span class="nav-number">5.</span> <span class="nav-text">三、交叉验证(cross validation)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#四模型评估指标精确率召回率f值rocauc"><span class="nav-number">6.</span> <span class="nav-text">四、模型评估指标（精确率、召回率、F值、ROC、AUC）</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Peter Tsung</span>
</div>

<!--
<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Muse
  </a>
</div>
<div class="powered-by">
<i class="fa fa-user-md"></i><span id="busuanzi_container_site_uv">
  本站访客数:<span id="busuanzi_value_site_uv"></span>
</span>
</div>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({"HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"], linebreaks: { automatic:true }, EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50) },
            tex2jax: { inlineMath: [ ["$", "$"], ["\\(","\\)"] ], processEscapes: true, ignoreClass: "tex2jax_ignore|dno",skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']},
                    TeX: {  noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } }, Macros: { href: "{}" } },
                            messageStyle: "none"
                                }); 
    </script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Queue(function() {
                    var all = MathJax.Hub.getAllJax(), i;
                            for(i=0; i < all.length; i += 1) {
                                            all[i].SourceElement().parentNode.className += ' has-jax';
                                                    }
                                                        });
        </script>
        <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

-->


        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.1"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.1"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.1"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.1"></script>



  


  




	





  





  





  






  





  

  

  

  

  


  <script type="text/javascript" src="/js/google-code-prettify/prettify.js"></script>
  <script type="text/javascript">
  $(window).load(function(){
     $('pre').addClass('prettyprint linenums').attr('style', 'overflow:auto;');
     prettyPrint();
   })    
  </script>
</body>
</html>
